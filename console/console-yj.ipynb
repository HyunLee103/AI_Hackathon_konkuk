{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1015_Final_w2v_ml_yj.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sLwNpPkwEUr"
      },
      "source": [
        "# NSMC 감성분석 data set\n",
        "- data load 및 generation\n",
        "- 간단한 EDA 와 ml 모델 돌리기\n",
        "- Feature Engineering 시에는 다양한 노트북 참고 예정  \n",
        "- Updated 1014\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsVtEBGDJv2g"
      },
      "source": [
        "## result list\n",
        "|data set|corpus|model|accuracy|비고|\n",
        "|------|---|---|---|---|\n",
        "|141000개|corpus 초기 494|NB|0.8129517728879261|valid test|\n",
        "|141000개|corpus 초기 494|DT|0.6820430965682363|valid test|\n",
        "|141000개|corpus 초기 494|KNN|801527761942766|valid test|\n",
        "|corpus로 거름|500개|NB|0.8127225013731514|test set, emb만 사용|\n",
        "|corpus로 거름|500개|DT|0.6799031674024045|test set, emb만 사용|\n",
        "|corpus로 거름|500개|NB|0.812498728563582|test set, emb300|\n",
        "|corpus로 거름|500개|DT|0.6684093821836158|test set, emb300|\n",
        "|corpus로 거름|500개|DT|0.7213011371727323|test set, emb50|\n",
        "\n",
        "|corpus로 거름|10000개||\n",
        "\n",
        "0.7213011371727323\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSMBDux9BeIL",
        "outputId": "09e645e0-ecb1-4f7e-9351-629f8db5afd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05jUkiZDupu-",
        "outputId": "6c91076a-c0fc-45ce-ac8c-09d7e50ccd49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My Drive/AI_assignment/hackathon_1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/AI_assignment/hackathon_1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndPBOX4lw_SA"
      },
      "source": [
        "# ready\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import sys\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "import os\n",
        "import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "import pickle\n",
        "import joblib\n",
        "\n",
        "from IPython.display import display\n",
        "pd.options.display.max_rows = 999\n",
        "pd.options.display.max_columns = 999\n",
        "\n",
        "import re\n",
        "\n",
        "# visualization\n",
        "from matplotlib import pyplot as plt\n",
        "plt.style.use('seaborn')\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxK_aOP33Uym"
      },
      "source": [
        "# Font\n",
        "import matplotlib.font_manager as fm\n",
        "fm._rebuild()\n",
        "plt.rc('font', family='NanumGothic')\n",
        "plt.rc('axes', unicode_minus=False)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfvVBj3IalQ-"
      },
      "source": [
        "# kras\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# sklearn\n",
        "from sklearn.model_selection import train_test_split,KFold\n",
        "#from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.ensemble import BaggingClassifier, VotingClassifier"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJV46kelbB89"
      },
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tw_xda8Uwg3f"
      },
      "source": [
        "### 1) Load Data\n",
        "데이터 형식  \n",
        "ID \\t document \\t label (0:neg / 1:pos) 로 공지 \n",
        "\n",
        "token <- 한글, duplicate, nan 날림, 형용사 명사 부사 남김, 불용어뺌"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQHUEBFMP3Cg"
      },
      "source": [
        "# train by hyun\n",
        "# train_token= joblib.load(os.path.join('data','train_tokens.pickle'))\n",
        "# train_label= joblib.load(os.path.join('data','train_label.pickle'))\n",
        "\n",
        "# train by moon\n",
        "train_token= joblib.load(os.path.join('data','train_moong.pickle'))\n",
        "train_label= joblib.load(os.path.join('data','train_label.pickle'))\n",
        "\n",
        "# test \n",
        "test_token = joblib.load(os.path.join('data','test_moong.pickle'))\n",
        "test_label = joblib.load(os.path.join('data','test_label_moong.pickle'))\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeSadYXVRaW1"
      },
      "source": [
        "train 데이터 갯수 : 146182  \n",
        "test 데이터 갯수 : 49157  \n",
        "corpus 단어 갯수 : tfidf_vocab500, tfidf_vocab10000\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN0ezL0fR840"
      },
      "source": [
        "### 2) Word2Vec\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bf2MRLiIiv1"
      },
      "source": [
        "# setting\n",
        "token = train_token\n",
        "dim = 128\n",
        "\n",
        "emb_model = Word2Vec(token, size=dim, window=3, min_count=1, iter=100, sg=1)\n",
        "\n",
        "# save\n",
        "emb_model.save('model/word2vec128_train.model')\n",
        "\n",
        "# # load model\n",
        "# # emb_model = joblib.load(os.path.join('model','word2vec_train_1015.model'))\n",
        "# emb_model = Word2Vec.load('model/word2vec128_train_.model')\n",
        "\n",
        "\n",
        "# 12분\n",
        "def make_w2v_mat(word_token_list, dim):\n",
        "    # word dict\n",
        "    word_table = {\n",
        "        word : vec for word, vec in zip(\n",
        "            emb_model.wv.index2word,\n",
        "            np.array(emb_model.wv.syn0)\n",
        "        )\n",
        "    }\n",
        "\n",
        "    emb_mat = np.zeros((len(word_token_list),dim))\n",
        "\n",
        "    for i,morphs in enumerate(word_token_list):\n",
        "        vector = np.array([\n",
        "                    word_table[morph] for morph in morphs \n",
        "                    if morph in word_table\n",
        "                ])\n",
        "        if vector.size != 0:\n",
        "            final_vector = np.mean(vector,axis=0)\n",
        "            emb_mat[i] = final_vector\n",
        "    \n",
        "    return emb_mat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIQWgWEEeQtH",
        "outputId": "ab626e24-bd95-4baf-836e-777744dac203",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Data generation\n",
        "train_emb_mat = make_w2v_mat(train_token,dim)\n",
        "test_emb_mat = make_w2v_mat(test_token,dim)\n",
        "\n",
        "print(train_emb_mat.shape, test_emb_mat.shape)\n",
        "\n",
        "\n",
        "# setting\n",
        "X_train, X_test, y_train, y_test = train_emb_mat, test_emb_mat, train_label, test_label "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(145791, 128) (49157, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnJ6G9ksRtUz"
      },
      "source": [
        "### 3) Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XjNBK7mQ1mQ"
      },
      "source": [
        "# ml model\n",
        "knn = KNeighborsClassifier()\n",
        "dt = DecisionTreeClassifier()\n",
        "nb = GaussianNB()\n",
        "svm = SVC()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyjJvCWDIcoI"
      },
      "source": [
        "def model_eval(model,X_train, X_test, y_train, y_test, save_model_name):\n",
        "    \n",
        "    #X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3, random_state=42)\n",
        "    \n",
        "    clf = model.fit(X_train,y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    acc = accuracy_score(y_test,y_pred)\n",
        "    print(model,' accuracy : ', acc)\n",
        "\n",
        "    # save model\n",
        "    with open('model/train_' + save_model_name + '.pickle', 'wb') as f:\n",
        "        pickle.dump(model, f, pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "    return acc"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcteBs9uApwF",
        "outputId": "a4937e0c-1afa-4f22-d78f-aab85e205ca8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# SVM 빨리 돌리는 코드\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "estimator = nb\n",
        "\n",
        "n_estimators = 10\n",
        "n_jobs = -1\n",
        "model = BaggingClassifier(base_estimator=estimator,\n",
        "                          n_estimators=n_estimators,\n",
        "                          max_samples=0.1 ,max_features=1.0,\n",
        "                          n_jobs=n_jobs)\n",
        "\n",
        "model.fit(X_train,y_train)\n",
        "accuracy_score(model.predict(X_test),y_test)\n",
        "\n",
        "# svm 0.7672762780478873\n",
        "# knn 0.763370425371768 8분\n",
        "# dt 0.7054539536586855 7초\n",
        "# nb 0.7519986980491079"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7290924995422828"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om8_OtR8iO_Q",
        "outputId": "97f88039-fa86-42e4-dc73-00cf4f0360a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# embedding 128 차원\n",
        "# NB\n",
        "print(model_eval(nb,X_train, X_test, y_train, y_test, 'emb128_nb'))\n",
        "print('-'*50)\n",
        "\n",
        "# dt\n",
        "%time print(model_eval(dt,X_train, X_test, y_train, y_test, 'emb128_dt'))\n",
        "print('-'*50)\n",
        "\n",
        "# knn\n",
        "# %time print(model_eval(knn,X_emb, X_test_emb, y_train, y_test, 'model/emb128_knn_voca500'))\n",
        "# print('-'*50)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GaussianNB(priors=None, var_smoothing=1e-09)  accuracy :  0.7306385662265802\n",
            "0.7306385662265802\n",
            "--------------------------------------------------\n",
            "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best')  accuracy :  0.6427161950485181\n",
            "0.6427161950485181\n",
            "CPU times: user 41.5 s, sys: 7.93 ms, total: 41.6 s\n",
            "Wall time: 42.7 s\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWK-hIIihCVA"
      },
      "source": [
        "## Ensemble Voting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MZF3UxqdB4Z"
      },
      "source": [
        "def Voting (X,y, model1, model2, model3=None, model4=None, model5=None):\n",
        "    eclf = VotinClassifier(estimators=[\n",
        "                                       ('model1', model1),\n",
        "                                       ('model2', model2),\n",
        "                                       ('model3', model3),\n",
        "                                       ('model4', model4),\n",
        "                                       ('model5', model5)\n",
        "                                       ], voting='soft')\n",
        "    eclf = eclf.fit(X,y)\n",
        "    return eclf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SashFq2IvYV6"
      },
      "source": [
        "# Ensemble & Evaluate\n",
        "eclf = Voting(X_train, y_train, nb_w2v, dt_w2v, svm_bag_wvv)\n",
        "y_pred = eclf.predict(X_test)\n",
        "\n",
        "accuracy_score(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNLgVGs8vYYV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BozA3qNnvYbC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2xsdscuvYdu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGtuWLI4vYgE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}