{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 거친 데이터셋 불러오기\n",
    "import pickle \n",
    "with open('train_data.pickle', 'rb') as fr:\n",
    "    train_data = pickle.load(fr)\n",
    "with open('test_data.pickle', 'rb') as fr:\n",
    "    test_data = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykospacing import spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 띄어쓰기 보정\n",
    "train_data['doc_spaced'] = train_data['document'].swifter.apply(lambda x:spacing(x))\n",
    "test_data['doc_spaced'] = test_data['document'].swifter.apply(lambda x:spacing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                    아 더빙 진짜 짜증나네요 목소리\n",
      "1                           흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나\n",
      "2                                    너무재밓었다그래서보는것을추천한다\n",
      "3                            교도소 이야기구먼 솔직히 재미는 없다평점 조정\n",
      "4    사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...\n",
      "Name: document, dtype: object\n",
      "0                                    아 더빙 진짜 짜증나네요 목소리\n",
      "1                       흠포스터 보고 초딩 영화 줄오버 연기조차 가볍지 않구나\n",
      "2                               너무 재밓었다 그래서 보는 것을 추천한다\n",
      "3                           교도소 이야기구먼 솔직히 재미는 없다 평점 조정\n",
      "4    사이몬 페그의 익살스런 연기가 돋보였던 영화 스파이더맨에서 늙어 보이기만 했던 커스...\n",
      "Name: doc_spaced, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 띄어쓰기 보정 테스트\n",
    "print(train_data['document'].head())\n",
    "print(train_data['doc_spaced'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "    \"\"\"\n",
    "    형태소로 분리 및 조사는 제거\n",
    "    \"\"\"\n",
    "    tokenizer = Okt()\n",
    "    morphs_pos = tokenizer.pos(sentence)\n",
    "    return [mp[0] for mp in morphs_pos if mp[1] != 'Josa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92acc48e0fa6429c928788d88682fd3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=145791.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00339eea8b3c40d9901d4ebaeb8fd01a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=48995.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 토큰화하기 (Control)\n",
    "train_data['doc_cleaned'] = train_data['document'].progress_apply(tokenize)\n",
    "test_data['doc_cleaned'] = test_data['document'].progress_apply(tokenize)\n",
    "\n",
    "# 데이터셋 토큰화하기 (Spaced)\n",
    "train_data['doc_cleaned_spaced'] = train_data['doc_spaced'].progress_apply(tokenize)\n",
    "test_data['doc_cleaned_spaced'] = test_data['doc_spaced'].progress_apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacingABtest(doc_name):\n",
    "    train = train_data[doc_name].values\n",
    "    test = test_data[doc_name].values\n",
    "\n",
    "    y_train = train_data['label'].values\n",
    "    y_test = test_data['label'].values\n",
    "\n",
    "    # TFIDF 주요 단어 추출 \n",
    "    X_train = np.array(train)\n",
    "    train_pos = X_train[y_train == 1]\n",
    "    train_neg = X_train[y_train == 0]\n",
    "\n",
    "    tfidfv = TfidfVectorizer(preprocessor=' '.join, max_features=30000).fit(train_pos)\n",
    "    score = {key : value for key, value in zip(sorted(tfidfv.vocabulary_, key = lambda x : tfidfv.vocabulary_[x]), tfidfv.transform(train_pos).toarray().sum(axis=0))}\n",
    "    top_pos = sorted(score, key = lambda x : score[x],reverse=True)[:10000]\n",
    "\n",
    "    tfidfv = TfidfVectorizer(preprocessor=' '.join, max_features=30000).fit(train_neg)\n",
    "    score = {key : value for key, value in zip(sorted(tfidfv.vocabulary_, key = lambda x : tfidfv.vocabulary_[x]), tfidfv.transform(train_neg).toarray().sum(axis=0))}\n",
    "    top_neg = sorted(score, key = lambda x : score[x],reverse=True)[:10000]\n",
    "\n",
    "    top = top_pos + top_neg\n",
    "\n",
    "    # Countervectorize \n",
    "    train = list(map(' '.join, train))\n",
    "    test = list(map(' '.join, test))\n",
    "\n",
    "    vectorizer = CountVectorizer()\n",
    "    vectorizer.fit(top)\n",
    "    X_train = vectorizer.transform(train).toarray()\n",
    "    X_test = vectorizer.transform(test).toarray()\n",
    "\n",
    "    # 성능 테스트 \n",
    "    nbc = MultinomialNB()\n",
    "    nbc.fit(X_train, y_train)\n",
    "    y_pred = nbc.predict(X_test)\n",
    "    \n",
    "    return accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 정확도(Control): 0.832\n",
      "테스트 정확도(Spaced): 0.830\n"
     ]
    }
   ],
   "source": [
    "name_control = 'doc_cleaned'\n",
    "name_spaced = 'doc_cleaned_spaced'\n",
    "\n",
    "print(\"테스트 정확도(Control): {:.3f}\".format(spacingABtest(name_control)))\n",
    "print(\"테스트 정확도(Spaced): {:.3f}\".format(spacingABtest(name_spaced)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
